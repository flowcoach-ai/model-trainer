{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T04:41:12.604384Z",
     "start_time": "2023-08-25T04:41:11.240015Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "404\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "INPUT_DIM = 101 # X is 101-dimensional\n",
    "HIDDEN_DIM = INPUT_DIM * 4 # Center-most latent space vector will have length of 404\n",
    "NUM_CLASSES = 15 # 16 classes\n",
    "\n",
    "print(INPUT_DIM)\n",
    "print(HIDDEN_DIM)\n",
    "print(NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T04:41:12.615086Z",
     "start_time": "2023-08-25T04:41:12.610234Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of MLP(\n",
      "  (fc1): Linear(in_features=101, out_features=202, bias=True)\n",
      "  (fc2): Linear(in_features=202, out_features=404, bias=True)\n",
      "  (fc3): Linear(in_features=404, out_features=202, bias=True)\n",
      "  (fc4): Linear(in_features=202, out_features=101, bias=True)\n",
      "  (fc5): Linear(in_features=101, out_features=50, bias=True)\n",
      "  (fc6): Linear(in_features=50, out_features=15, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, input_dim * 2)\n",
    "        self.fc2 = nn.Linear(input_dim * 2, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, int(hidden_dim / 2))\n",
    "        self.fc4 = nn.Linear(int(hidden_dim / 2), int(hidden_dim / 4))\n",
    "        self.fc5 = nn.Linear(int(hidden_dim / 4), int(hidden_dim / 8))\n",
    "        self.fc6 = nn.Linear(int(hidden_dim / 8), num_classes)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        z = F.relu(self.fc1(x_in))  # ReLU activation function added!\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = F.relu(self.fc3(z))\n",
    "        z = F.relu(self.fc4(z))\n",
    "        z = F.relu(self.fc5(z))\n",
    "        z = self.fc6(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = MLP(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, num_classes=NUM_CLASSES)\n",
    "print(model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T04:41:12.645129Z",
     "start_time": "2023-08-25T04:41:12.616543Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=101, out_features=202, bias=True)\n",
       "  (fc2): Linear(in_features=202, out_features=404, bias=True)\n",
       "  (fc3): Linear(in_features=404, out_features=202, bias=True)\n",
       "  (fc4): Linear(in_features=202, out_features=101, bias=True)\n",
       "  (fc5): Linear(in_features=101, out_features=50, bias=True)\n",
       "  (fc6): Linear(in_features=50, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T04:41:12.645337Z",
     "start_time": "2023-08-25T04:41:12.634643Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m X_infer \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(sample) \u001b[38;5;66;03m# all 101(or 102?) features\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Standardize\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m X_infer \u001b[38;5;241m=\u001b[39m \u001b[43mX_scaler\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X_infer)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_infer)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Inputs for inference\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "current_folder = globals()['_dh'][0]\n",
    "csv_path = os.path.join(current_folder, 'training_set.csv')\n",
    "df = pd.read_csv(csv_path, header=0) # load\n",
    "hi = '0.6276978850364685,0.5843755602836609,-0.22295062243938446,0.6268095374107361,0.5737197995185852,-0.20632241666316986,0.626587986946106,0.5743216872215271,-0.20632290840148926,0.6263055801391602,0.5748404860496521,-0.20634683966636658,0.624580979347229,0.5716469883918762,-0.23019017279148102,0.6226451396942139,0.5708016157150269,-0.2302272915840149,0.6204419732093811,0.569793701171875,-0.23026911914348602,0.6164519190788269,0.5789487361907959,-0.11819145828485489,0.60848069190979,0.5737546682357788,-0.2259415239095688,0.6218960881233215,0.6019092202186584,-0.18988178670406342,0.6198330521583557,0.5968146324157715,-0.22149603068828583,0.569865882396698,0.6342253088951111,0.013678950257599354,0.5751160979270935,0.654432475566864,-0.28310051560401917,0.5595629811286926,0.7733974456787109,0.015326440334320068,0.5656692981719971,0.7923648357391357,-0.32690662145614624,0.5588405132293701,0.8882727026939392,-0.054843779653310776,0.5610483288764954,0.930568277835846,-0.3327784538269043,0.5656618475914001,0.8991759419441223,-0.04507143795490265,0.5689927935600281,0.9615245461463928,-0.3773484528064728,0.5691770911216736,0.9094014763832092,-0.08489023894071579,0.5727695226669312,0.9585964679718018,-0.35044315457344055,0.5621487498283386,0.9082633256912231,-0.0723174437880516,0.567960798740387,0.9476576447486877,-0.3250153958797455,0.47402092814445496,0.7038294672966003,0.08810194581747055,0.45962613821029663,0.7189508676528931,-0.08809611946344376,0.5689114928245544,0.7234283685684204,0.16465863585472107,0.3733466565608978,0.8305726051330566,-0.11438359320163727,0.5591745376586914,0.8977935910224915,0.24112708866596222,0.2668099105358124,0.8921425938606262,-0.06320709735155106,0.5496239066123962,0.9240500926971436,0.24600288271903992,0.253009170293808,0.8905003666877747,-0.059814102947711945,0.5976037383079529,0.9380369782447815,0.23735664784908295,0.2811347544193268,0.9561828374862671,-0.11795039474964142,0,1,0'\n",
    "ok = hi.split(',')\n",
    "\n",
    "column_headers = df.columns.tolist()\n",
    "column_headers.pop()\n",
    "\n",
    "sample = [{header: ok[i]} for i, header in enumerate(column_headers)]\n",
    "\n",
    "X_infer = pd.DataFrame(sample) # all 101(or 102?) features\n",
    "\n",
    "# Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the data (mean=0, std=1) using training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_infer = X_scaler.transform(X_infer)\n",
    "print(X_infer)\n",
    "# Predict\n",
    "y_infer = F.softmax(model(torch.Tensor(X_infer)), dim=1)\n",
    "prob, _class = y_infer.max(dim=1)\n",
    "label = label_encoder.inverse_transform(_class.detach().numpy())[0]\n",
    "print (f\"The probability that you have {label} is {prob.detach().numpy()[0]*100}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
